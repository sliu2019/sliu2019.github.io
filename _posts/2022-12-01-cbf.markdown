---
layout: post
title:  "Safe Control Under Input Limits with Neural Control Barrier Functions"
date:   2022-12-01 00:00:00 +00:00
image: /images/ncbf_flying_inv_pend.png
categories: research
author: "Simin Liu"
authors: "Simin Liu, Changliu Liu, John Dolan"
venue: "Conference on Robot Learning"
arxiv: https://arxiv.org/abs/2211.11056
slides: /pdfs/neural_cbf_slides.pdf
code: https://github.com/sliu2019/input_limit_cbf
---

The work below and its alternatives can only scale to 5-7 D systems. We created a much more scalable technique using adversarial training of neural CBFs. Essentially, our method trades the theoretical guarantees of safety for scalability and strong empirical guarantees (>99% safe). Currently, this class of methods has been shown to scale to >20D. This includes complex systems, like balancing quadrotors and many-linked manipulators.